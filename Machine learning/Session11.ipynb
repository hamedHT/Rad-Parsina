{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0836e215-1edd-405b-b42f-8730c4bf3a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2756\n",
      "\n",
      "Sample document:\n",
      "\n",
      "\n",
      ":So we try to ensure that the process of deciding whether to introduce\n",
      ":third parties isn't random.  As Steve said above, there are examples\n",
      ":where third parties *are* less ignorant or corrupt than the two\n",
      ":primary parties; should this knowledge not be able to help?\n",
      "\n",
      "Of course it helps,  but only if the decision to involve third parties\n",
      "is the primary partis' to make.  A corrupt and ignorant third party\n",
      "isn't going to say,  \"we're corrupt and ignorant,  we'll stay out of this\".\n",
      "Pointing out th\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "categories = ['rec.sport.baseball', 'sci.space', 'talk.politics.misc']  # Select specific categories\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Display sample data\n",
    "print(f\"Number of documents: {len(dataset.data)}\")\n",
    "print(\"\\nSample document:\")\n",
    "print(dataset.data[0][:500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e487021-76e7-46b7-99ba-2dc267941287",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)  # Limit to top 1000 features\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f297a73-54d2-4d70-8edf-93e036824432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Matrix Shape: (2756, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTF-IDF Matrix Shape: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "402fdfa4-da09-4ca1-8346-bae838888d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a0adf1e-112e-4f04-99c6-8455678e9c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix Shape: (2756, 2756)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cosine Similarity Matrix Shape: {cosine_sim.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39a49b9a-eb61-46b8-9c1d-4cede5946c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_documents(doc_index, cosine_sim=cosine_sim, top_n=5):\n",
    "    # Get pairwise similarity scores for the given document\n",
    "    sim_scores = list(enumerate(cosine_sim[doc_index]))\n",
    "    \n",
    "    # Sort documents based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top N most similar documents (excluding the document itself)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    doc_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Return the titles (or content) of the recommended documents\n",
    "    return [dataset.data[i] for i in doc_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "518b12ac-5c0b-4a0e-aed6-e803016c91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = 0  # Index of the document to find similar documents for\n",
    "recommended_docs = recommend_similar_documents(doc_index, cosine_sim, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8aab8566-70b5-4e15-9135-4da1ceec0be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Documents:\n",
      "\n",
      "Document 1:\n",
      "\n",
      "cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck\n",
      "cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs scuk\n",
      "cubs suck cubs suck cubs suck cubs cuck cubs suck cubs suck cubs suck\n",
      "cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck\n",
      "cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck cubs suck\n",
      "\n",
      "oh yeah, he aqlso added that harry is a drunken idiot who shoulda\n",
      "stayed in st louis where his heart is, but also added that fair weathered\n",
      "fans all\n",
      "\n",
      "Document 2:\n",
      "I've noticed that is has become fashionable lately in rsb to predict\n",
      "the Marlines to finish ahead of the Cubs....how?\n",
      "\n",
      "First Base:\n",
      "\n",
      "Grace vs Destrade...Could Destrade be the second coming of Cecil\n",
      "Fielder? I doubt it. If Destrade performs to the height of expectations,\n",
      "then even, otherwise, edge to Cubs\n",
      "\n",
      "Second Base:\n",
      "\n",
      "Sandberg vs Barberie...No contest. Sandberg will be back May 1. Edge\n",
      "to Cubs...a big edge.\n",
      "\n",
      "Shortstop:\n",
      "\n",
      "Vizcaino vs Weiss...Vizcaino is excellent defensively, but is an\n",
      "automatic o\n",
      "\n",
      "Document 3:\n",
      "Boy, hats off to any Cubs fan who can actually muster up the courage to put\n",
      "down Braves fans.  I mean, all the Braves have done is gone to two consecutive\n",
      "world series.  Also, being the Cubs fan that I am, I really have to hand it to\n",
      "all the Braves fans out there that are capable of driving me crazy with that\n",
      "infernal cheer that they have.  \n",
      "\n",
      "However, I do have to protest anyone saying that all Cubs fans are stupid.  The\n",
      "way I see it, either I'm just too stupid to acknowledge it, or that observa\n",
      "\n",
      "Document 4:\n",
      "Newsgroups: rec.sport.baseball\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Harry talks about this \"incident\" in his autobiography \"Holy Cow.\"  \n",
      "Unfortunately, I can not clarify on this since (1) I read the book a couple\n",
      "of years ago and (2) I do not have my book with me.  \n",
      "\n",
      "Anyway, It is a pretty interesting book if you are a Harry or Cubs fan.\n",
      "\n",
      "Document 5:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I like the Mariners a lot, but my heart belongs to the Cubs...You can imagine\n",
      "my frustration when I saw the Cubs nabbing LeFebvre...ARHGGHRGHH!\n",
      "\n",
      "-John Neuharth\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRecommended Documents:\")\n",
    "for i, doc in enumerate(recommended_docs, 1):\n",
    "    print(f\"\\nDocument {i}:\")\n",
    "    print(doc[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
